<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on BinGo&#39;s Blog</title>
    <link>https://aka-bingo.github.io/posts/</link>
    <description>Recent content in Posts on BinGo&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Sep 2019 23:45:08 +0800</lastBuildDate>
    
	<atom:link href="https://aka-bingo.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>MySQL 同步复制的思考</title>
      <link>https://aka-bingo.github.io/2019/09/mysql-%E5%90%8C%E6%AD%A5%E5%A4%8D%E5%88%B6%E7%9A%84%E6%80%9D%E8%80%83/</link>
      <pubDate>Tue, 17 Sep 2019 23:45:08 +0800</pubDate>
      
      <guid>https://aka-bingo.github.io/2019/09/mysql-%E5%90%8C%E6%AD%A5%E5%A4%8D%E5%88%B6%E7%9A%84%E6%80%9D%E8%80%83/</guid>
      <description>内容介绍 虽然互联网上已经充斥着 MySQL 的主从复制相关文章，其中不乏优质精准的解析。但之前的学习过程还是数次被误导，一些比较好奇的问题也没有弄懂，今天这篇文章针对之前学习过程中的一些困惑做出解答和记录。
本文假设读者在阅读之前已经对数据库的主从复制有了基本的了解，如果完全不清楚请先谷歌百度查阅优秀的文档教程，这里就不画蛇添足了，文章主要包括以下内容：
 MySQL 为什么需要复制这个功能 复制带来了什么额外开销 如何监听触发复制的行为 - PUSH or PULL 双主结构如何避免死循环 数据一致性和服务性能的取舍  在开始阅读前，请仔细查看下面这张经典的 MySQL主从复制架构图（根据个人认知做了部分修改），图中的内容将在之后的阅读中起到极大的帮助。
MySQL 为什么需要复制这个功能  数据分布  作为一个互联网服务，服务的对象可以是世界上任意一个角落的人们。但是数据与人的距离产生的延时和导致用户体验有时是难以接受的。异地数据中心是常见的解决方案，而支持这一方案的就是 MySQL 的复制功能。
 负载均衡  大部分互联网应用都是对数据的 CRUD 操作，并且读取的占比往往是远超写入等其他操作的，通过 MySQL 复制功能构建的主备数据库结构，可以很好地分散应用对单一数据库的数据读取压力，改善读密集型应用的性能，提高服务的吞吐量。
 数据安全  数据的安全保障无疑需要通过冗余备份来作为最后一道防线，虽然复制不等于备份，但是却是一项实用且有意义的技术补充。
 高可用性  现今的互联网服务一旦宕机，带来的往往是灾难性的后果。一个通过复制功能实现的主备故障切换系统能够极大地缩短系统宕机时间，甚至实现无感知的过渡，保障服务的高可用性。
复制带来了什么额外开销 复制是两个数据节点（主库和从库）之间的数据流转，在此我们区分讨论：
 主库开销
 总所周知（假设），主库在数据复制的过程中相比单一的数据节点，它额外地将数据变更记录在了二进制文件 binary log 中。这也是复制过程中主库的主要开销。
 在从库对主库进行连接的时候，通过从库的注册信息，主库会为每一个从库建立一个连接用于数据传输，这里又会带来额外的调度开销和网络 I/O 开销。当从库向主库申请读取较旧的二进制文件时（比如从库第一次和主库进行复制同步，请求了所有的 binary log ），会造成极高的 I/O 开销。同样的，当设置的从库越多，对应的开销也会对应累加。
  从库开销
 从库在复制过程中，通过 I/O 线程将主库的 binary log 事件写入到本地的 relay log 中，这会带来额外的磁盘 I/O 开销。对 relay log 的写入负载取决于传输的数据量。 其次，从库通过 SQL 线程对 relay log 中的事件进行读取和重放实现数据的复制。这也会带来额外的磁盘 I/O 开销。但是如果 SQL 线程和 I/O 线程保持一致，通常可以从系统缓存中获取 relay log 事件来节省开销。   总的来说，相比于复制带来的优点，如数据安全，负载均衡&amp;hellip; 以上列举的开销是必要的且十分可以接受的。</description>
    </item>
    
    <item>
      <title>Golang Channel 学习笔记</title>
      <link>https://aka-bingo.github.io/2019/09/golang-channel-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 03 Sep 2019 20:49:19 +0800</pubDate>
      
      <guid>https://aka-bingo.github.io/2019/09/golang-channel-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>简介 Channel 是 Go 语言中并发模型的重要组成部分，可以在不同的 goroutine 之间进行数据的传输。
在日常使用中，channel 可以分为两种：
 无缓冲 channel：在无缓冲 channel 中，数据的发送和读取操作需要同时进行，当只有一个 goroutine A 进行数据的读取（写入）时，需要等待另一个 goroutine B 通过这个 channel 进行数据写入（读取）。在此之前 goroutine A 会一直阻塞，直到 goroutine B来拯救它。 有缓冲 channel：在有缓冲 channel 中，会自带一个缓冲循环队列。当 goroutine 进行数据读取时，如果缓冲队列中有数据便直接读取，如果没有便阻塞等待其他 goroutine 写入数据。当 goroutine 进行数据写入时，如果缓冲队列没有满，则直接写入数据后离开。如果缓冲队列已满，则需要等待其他 goroutine 来消费缓冲队列，才能继续写入，在此之前只能一直阻塞。  Channel 数据结构 首先，我们看一下 Go 语言中 Channel 的数据结构：
# go1.13:src/runtime/chan.go:32 type hchan struct { qcount uint // 当前channel中元素的个数 dataqsiz uint // 循环队列的长度 buf unsafe.Pointer // 指针, 指向一个长度为dataqsize的数组, 即缓冲队列 elemsize uint16 // channel可以接收的元素大小(单个) closed uint32	// channel的关闭状态 elemtype *_type // channel可以接收的元素类型 sendx uint // 标示当前可发送元素的位置(数组下标) recvx uint // 标示当前可接收元素的位置(数组下标) recvq waitq // 阻塞的接收 goroutine 队列 sendq waitq // 阻塞的发送 goroutine 队列 // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel.</description>
    </item>
    
    <item>
      <title>MySQL 多版本并发控制</title>
      <link>https://aka-bingo.github.io/2019/05/mysql-%E5%A4%9A%E7%89%88%E6%9C%AC%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/</link>
      <pubDate>Sat, 25 May 2019 15:47:10 +0800</pubDate>
      
      <guid>https://aka-bingo.github.io/2019/05/mysql-%E5%A4%9A%E7%89%88%E6%9C%AC%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/</guid>
      <description>什么是多版本并发控制（ MVCC ） MySQL 的大多数事务型存储引擎基于提升并发性能的考虑，一般都实现了多版本并发控制（ MVCC ）。MVCC 是行级锁的一个变种，但实际上实现机制有所不同，避免了加锁的操作，因此有了更低的开销和更高的性能。
MVCC 的实现，是通过保持数据在某个时间点的快照来实现的，不管事务的执行时间有多久，MVCC 保障了每一个事务内看到的数据是一致的，而根据事务开始时间，不同事务看到同一张表，同一份数据可能是不同的。
不同存储引擎对 MVCC 的实现机制不尽相同，因为 MVCC 并没有一个统一的标准，下面以 InnoDB 为例，简要介绍 MVCC 的实现原理。
InnoDB 中的 MVCC InnoDB 中的 MVCC，是通过在每行记录后保存两个隐藏的列来实现的。这两个特殊的列一个保存了行的创建时间，一个保存了行的删除时间。当然这里存储的并不是真实的时间，实际上存储的是版本号（ system version number ）。每次开启一个新的事务，系统版本号会开始递增并分配给当前的事务，用于与数据的版本号进行比较。简要介绍下 InnoDB 是如何操作的：
 SELECT：在 InnoDB 中，SELECT 操作有两个额外的条件：  只查找行的创建版本号小于或等于当前事务版本号的数据。这样可以保证事务读取的数据要么是在事务开始之前就已经存在，要么是事务本身插入或者修改过的。 行的删除版本号要么未定义，要么大于当前事务的版本号。这样是为了确保事务读取的数据在事务开始之前未被删除。  INSERT：InnoDB 为每行新增数据设置了当前事务的版本号作为创建版本号，删除版本号留空。 DELETE：InnoDB 为每行删除的数据设置了当前事务的版本号作为删除版本号。 UPDATE：InnoDB 额外插入一条新的记录，将当前事务版本号作为新记录的创建版本号，同时保存当前事务版本号到原来的数据中的删除版本号。  在 InnoDB 中，MVCC 只在 READ COMMITTED 和 REPEATABLE READ 这两个隔离级别下工作。其他的隔离级别和 MVCC 并不兼容，READ UNCOMMITTED 总是读取最新的数据，而 SERIALIZABLE 则会对所有读取的行都进行加锁操作。
总结 MVCC 解决了多个事务并发过程中产生的幻读问题。通过保存额外的两个系统版本号字段，使得大部分读操作可以不用加锁，提高了读取性能的同时也保障了读取范围的可靠性。唯一的不足是每行数据都需要额外的存储空间，以及需要更多的行检查和维护工作，但是在数据读取保障和性能方面的巨大提升前提下，这些不足便显得十分容易接受了。</description>
    </item>
    
    <item>
      <title>数据库事务隔离级别</title>
      <link>https://aka-bingo.github.io/2019/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</link>
      <pubDate>Wed, 22 May 2019 21:48:03 +0800</pubDate>
      
      <guid>https://aka-bingo.github.io/2019/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</guid>
      <description>定义  脏读（ Dirty Read ）：当事务 A 对数据进行修改后，事务 B 读取了被改动后的数据，此时事务 A 进行了异常回滚，事务B读取到的是未经提交的数据，称之为脏读。 不可重复读（ NonRepeatable Read ）：事务 A 中读取了数据后，事务 B 对数据进行了修改并提交，事务 A 再次对数据进行读取发现前后不一致，称之为不可重复读。 幻读（ Phantom Read ）：事务 A 在读取某个范围内的记录时，事务 B 在该范围内插入了新的记录，事务 A 再次进行数据统计后得到不同的结果，称之为幻读。  PS：不可重复读和幻读从结果上看十分相似，都是数据在两次读取间隔间进行修改导致两次读取的结果不一致，他们的区别在于：
 不可重复读指的是一个事务内对同一数据的多次读取的情况。 幻读指的是事务的读取范围被其他事务改变的情况。  隔离级别 在 SQL 标准中定义了四种隔离级别，每一种级别都规定了一个事务中所做的修改，哪些在事务内和事务间是可见或不可见的。较低级的隔离级别一般系统的开销也更低，可以支撑更高的并发，但是对上层应用的数据读取可能会造成影响。
READ UNCOMMITTED 未提交读 在 READ UNCOMMITTED 隔离级别下，事务可以对其他事务中尚未提交的数据修改进行读取。这个级别会导致很多问题，比如脏读，在实际应用中一般很少使用。
READ COMMITTED 提交读 在 READ COMMITTED 隔离级别下，一个事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的。该隔离级别避免了脏读的发生，但是一个事务内的查询，依然有可能获得不同的结果（数据被其他事务修改），导致产生不可重复读。
REPEATABLE READ 可重复读 REPEATABLE READ 解决了脏读&amp;amp;幻读的问题，该隔离级别保证了在同一个事务中多次读取同样的记录结果是一致的。但是该隔离级别依然会导致幻读的问题。
PS：在 SQL 标准中，REPEATABLE READ 无法解决幻读的问题，但是 MySQL 中 InnoDB 和 XtraDB 存储引擎通过多版本并发控制（ MVCC，MultiVersion Concurrency Control ）解决了幻读的问题。</description>
    </item>
    
    <item>
      <title>你好呀，2018</title>
      <link>https://aka-bingo.github.io/2018/02/%E4%BD%A0%E5%A5%BD%E5%91%802018/</link>
      <pubDate>Thu, 22 Feb 2018 22:34:47 +0800</pubDate>
      
      <guid>https://aka-bingo.github.io/2018/02/%E4%BD%A0%E5%A5%BD%E5%91%802018/</guid>
      <description>过去一年基本都懒得没怎么更新，新的一年要做出改变了，一些比较好的事情需要养成习惯，比如跑步、看书，记录生活的点滴吧。
说起跑步主要是因为去年长时间对着电脑工作，周末又懒，体型隐隐有发福的迹象，其实已经在发福了。新的一年和同事约好每周都去跑步，希望能坚持下来养成一个好习惯吧。毕竟对身体也是有好处的。
另一件事是看书。去年买了一些杂书，当然也有专业的书啦，不过基本没怎么看，目前看完的只有《宇宙简史》。新的一年每天都要抽个至少半个小时来看书吧。周末可以多点时间。平时很多时间浪费在漫无目的地上网逛视频，确实有点浪费了😭
过去一年进步其实不大，没有系统的学习曲线和目标，自制力也不足。新的一年主要深入研究一下 Golang 以及主流框架吧，后期尽量能够用 Go 做出一些东西，外包也好自己的脑洞也罢。另外需要把学到的写下来巩固记忆，不要等用到的时候又忘记了。尽量深入地了解各种事物而不是浮于表面，不然记忆下来的东西也是十分有限。
如果还有多余的时间的话，希望能当个天文学小迷弟哈哈哈哈哈。
这一次过年过得是真的很纠结，差点做了一些影响自己一生的决定。不知道是一个好的开始还是坏的，但是希望以后做的决定都能够充足地思考以及让自己不后悔吧。来到深圳第五年了，隐隐有了逃离的念头，现在也要开始对以后的走向认认真真地规划而不是空想了。
以上是2018年的 Flag，虽然全都是希望，2019年来验证一下是否变成现实吧！
​
 这篇文章是无意中在以前的博客（ Git Page ）看到的。回头看看其实很多事道理都懂但是意志力不够坚强没法贯彻，迁移到目前的 Blog 中半讽刺半鞭策一下自己吧。
 </description>
    </item>
    
  </channel>
</rss>